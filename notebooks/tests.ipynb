{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d0e1b1b",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa5d35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "import pandas as pd\n",
    "from typing import List, Tuple\n",
    "from scipy.optimize import linear_sum_assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead23927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Development imports with forced local package resolution and hot-reload\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import importlib\n",
    "\n",
    "# Ensure the repository root (the directory that contains \"domino/\") is on sys.path.\n",
    "# This makes \"import domino\" work even when running from a notebook folder.\n",
    "REPO_ROOT = Path.cwd()\n",
    "if not (REPO_ROOT / \"src\" / \"domino\").is_dir():\n",
    "    # If the notebook is inside a subfolder, walk up until we find \"domino/\"\n",
    "    for parent in Path.cwd().parents:\n",
    "        if (parent / \"src\" / \"domino\").is_dir():\n",
    "            REPO_ROOT = parent\n",
    "            break\n",
    "\n",
    "SRC_ROOT = REPO_ROOT / \"src\"\n",
    "if str(SRC_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC_ROOT))\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Hot-reload robusto (evita \"module X not in sys.modules\")\n",
    "# -----------------------------------------------------------------------------\n",
    "import importlib\n",
    "import sys\n",
    "\n",
    "def reload_module(modname: str):\n",
    "    \"\"\"\n",
    "    Reload a module by name, importing it first if needed.\n",
    "    This avoids inconsistencies between local variables and sys.modules.\n",
    "    \"\"\"\n",
    "    m = importlib.import_module(modname)\n",
    "    return importlib.reload(m)\n",
    "\n",
    "# Reload in a safe order (core utilities first, then higher-level modules)\n",
    "reload_module(\"domino.utils.constants\")\n",
    "reload_module(\"domino.utils.repro\")\n",
    "\n",
    "reload_module(\"domino.leiden.partitions_functions\")\n",
    "reload_module(\"domino.leiden.scoring\")\n",
    "reload_module(\"domino.leiden.leiden_engine\")\n",
    "\n",
    "reload_module(\"domino.bic_minimization.binary_bic\")\n",
    "reload_module(\"domino.bic_minimization.signed_bic\")\n",
    "reload_module(\"domino.bic_minimization.weighted_bic\")\n",
    "\n",
    "reload_module(\"domino.ergms_solvers.binary_solvers\")\n",
    "reload_module(\"domino.ergms_solvers.signed_solvers\")\n",
    "reload_module(\"domino.ergms_solvers.weighted_solvers\")\n",
    "\n",
    "reload_module(\"domino.represent_and_analyze\")\n",
    "reload_module(\"domino.detect\")  # always reload by full name\n",
    "\n",
    "from domino.detect import detect\n",
    "from domino.represent_and_analyze import partition_to_dict, community_layout, process_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e140ea9d",
   "metadata": {},
   "source": [
    "# Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5128dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ground_truth_with_domino(\n",
    "    G: nx.Graph,\n",
    "    truth: np.ndarray,\n",
    "    *,\n",
    "    pos: dict | None = None,\n",
    "    Apos: np.ndarray | None = None,\n",
    "    Aneg: np.ndarray | None = None,\n",
    "    layout: str = \"custom\",\n",
    "    title_prefix: str = \"groundtruth\",\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Render a ground-truth partition using the same post-processing and\n",
    "    visualization code employed by detect().\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    G : nx.Graph\n",
    "        Graph to be visualized.\n",
    "    truth : np.ndarray\n",
    "        Community labels aligned with node order 0..N-1.\n",
    "    pos : dict, optional\n",
    "        Fixed node positions to enforce identical geometry across plots.\n",
    "    Apos, Aneg : np.ndarray, optional\n",
    "        Signed layers used to trigger signed plotting.\n",
    "    layout : str\n",
    "        Layout keyword used by the package (\"custom\", \"kamada\", \"kshell\", \"auto\", \"community\").\n",
    "    title_prefix : str\n",
    "        Filename prefix used by the visualization backend (if saving is enabled).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Output dictionary returned by process_graph (colors, figures, etc.).\n",
    "    \"\"\"\n",
    "    viz_cfg: dict = {\n",
    "        \"enabled\": True,\n",
    "        \"layout\": layout,\n",
    "        \"prefix\": title_prefix,\n",
    "    }\n",
    "    if pos is not None:\n",
    "        viz_cfg[\"layout\"] = \"custom\"\n",
    "        viz_cfg[\"pos\"] = pos\n",
    "\n",
    "    # process_graph expects labels in any supported format; (N,1) is fine.\n",
    "    detected_labels = np.asarray(truth, dtype=int).reshape(-1, 1)\n",
    "\n",
    "    return process_graph(\n",
    "        G,\n",
    "        detected_labels,\n",
    "        Apos=Apos,\n",
    "        Aneg=Aneg,\n",
    "        viz=viz_cfg,\n",
    "        report=False,\n",
    "    )\n",
    "\n",
    "def truth_as_dict(truth: np.ndarray) -> dict[int, int]:\n",
    "    \"\"\"\n",
    "    Convert an array of ground-truth labels aligned with node order 0..N-1\n",
    "    into a node -> community dictionary.\n",
    "    \"\"\"\n",
    "    t = np.asarray(truth, dtype=int).reshape(-1)\n",
    "    return {int(i): int(t[i]) for i in range(len(t))}\n",
    "\n",
    "\n",
    "def _labels_from_any(G: nx.Graph, labels_like) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Map any supported label container into a (N,) integer array aligned with sorted(G.nodes()).\n",
    "\n",
    "    Supported inputs:\n",
    "      - dict: node -> label\n",
    "      - list / np.ndarray: labels in node order 0..N-1 (assumed)\n",
    "      - Partition-like: iterable of communities (iterables of nodes)\n",
    "    \"\"\"\n",
    "    nodes = sorted(G.nodes())\n",
    "    if isinstance(labels_like, dict):\n",
    "        return np.array([int(labels_like[n]) for n in nodes], dtype=int)\n",
    "\n",
    "    if isinstance(labels_like, (list, np.ndarray)):\n",
    "        y = np.asarray(labels_like, dtype=int).reshape(-1)\n",
    "        # If labels are provided as length-N aligned with node ids 0..N-1,\n",
    "        # sorted(nodes) is also [0..N-1] in all your synthetic tests.\n",
    "        return y\n",
    "\n",
    "    d = {}\n",
    "    for cid, comm in enumerate(labels_like):\n",
    "        for v in comm:\n",
    "            d[v] = cid\n",
    "    return np.array([int(d[n]) for n in nodes], dtype=int)\n",
    "\n",
    "\n",
    "def _relabel_consecutive(y: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Relabel integer labels to consecutive {0,1,...,K-1} preserving equivalence classes.\n",
    "    \"\"\"\n",
    "    _, inv = np.unique(np.asarray(y, dtype=int), return_inverse=True)\n",
    "    return inv\n",
    "\n",
    "\n",
    "def _contingency(y_true: np.ndarray, y_pred: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute contingency matrix C where C[a,b] counts nodes with true=a and pred=b,\n",
    "    after relabeling each set to consecutive integers.\n",
    "    \"\"\"\n",
    "    yt = _relabel_consecutive(y_true)\n",
    "    yp = _relabel_consecutive(y_pred)\n",
    "    kt = int(yt.max()) + 1\n",
    "    kp = int(yp.max()) + 1\n",
    "    C = np.zeros((kt, kp), dtype=int)\n",
    "    for a, b in zip(yt, yp):\n",
    "        C[a, b] += 1\n",
    "    return C\n",
    "\n",
    "\n",
    "def compare_partitions(G: nx.Graph, truth_labels, found_labels) -> dict:\n",
    "    \"\"\"\n",
    "    Compare two partitions in a label-invariant way via optimal label matching.\n",
    "\n",
    "    Returns a dictionary containing exact match flag, node accuracy, mapping between\n",
    "    predicted and true labels (after Hungarian matching), contingency matrix and\n",
    "    (if available) ARI/NMI.\n",
    "    \"\"\"\n",
    "    y_true = _labels_from_any(G, truth_labels)\n",
    "    y_pred = _labels_from_any(G, found_labels)\n",
    "    C = _contingency(y_true, y_pred)\n",
    "\n",
    "    # Hungarian matching to maximize matched nodes\n",
    "    cost = C.max() - C\n",
    "    r_ind, c_ind = linear_sum_assignment(cost)\n",
    "    matched = int(C[r_ind, c_ind].sum())\n",
    "    acc = matched / float(len(y_true))\n",
    "\n",
    "    mapping_pred_to_true = {int(pred): int(true) for true, pred in zip(r_ind, c_ind)}\n",
    "    exact = (C.shape[0] == C.shape[1]) and (acc == 1.0)\n",
    "\n",
    "    ari = nmi = None\n",
    "    try:\n",
    "        from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "        ari = float(adjusted_rand_score(_relabel_consecutive(y_true), _relabel_consecutive(y_pred)))\n",
    "        nmi = float(normalized_mutual_info_score(_relabel_consecutive(y_true), _relabel_consecutive(y_pred)))\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return {\n",
    "        \"exact_match\": bool(exact),\n",
    "        \"accuracy\": float(acc),\n",
    "        \"mapping_pred_to_true\": mapping_pred_to_true,\n",
    "        \"ari\": ari,\n",
    "        \"nmi\": nmi,\n",
    "        \"contingency\": C,\n",
    "    }\n",
    "\n",
    "\n",
    "def pretty_print_result(name: str, res: dict) -> None:\n",
    "    \"\"\"\n",
    "    Print a compact comparison report produced by compare_partitions().\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 78)\n",
    "    print(f\"{name} — Ground truth vs. detected\")\n",
    "    print(\"=\" * 78)\n",
    "    print(f\"Exact up to permutation : {res['exact_match']}\")\n",
    "    print(f\"Node accuracy           : {res['accuracy'] * 100:.2f}%\")\n",
    "    if res[\"ari\"] is not None:\n",
    "        print(f\"Adjusted Rand Index     : {res['ari']:.4f}\")\n",
    "    if res[\"nmi\"] is not None:\n",
    "        print(f\"Normalized Mutual Info  : {res['nmi']:.4f}\")\n",
    "\n",
    "    mapping_str = \", \".join([f\"P{p}→T{t}\" for p, t in sorted(res[\"mapping_pred_to_true\"].items())])\n",
    "    print(f\"Best label mapping      : {mapping_str if mapping_str else '(none)'}\")\n",
    "\n",
    "    C = res[\"contingency\"]\n",
    "    df = pd.DataFrame(\n",
    "        C,\n",
    "        index=[f\"T{i}\" for i in range(C.shape[0])],\n",
    "        columns=[f\"P{j}\" for j in range(C.shape[1])],\n",
    "    )\n",
    "    print(\"\\nContingency (rows=true, cols=pred):\")\n",
    "    print(df.to_string())\n",
    "\n",
    "\n",
    "def recap_line(prefix: str, res: dict) -> str:\n",
    "    \"\"\"\n",
    "    Build a one-line recap string for a compare_partitions() output.\n",
    "    \"\"\"\n",
    "    s = f\"{prefix}: acc={res['accuracy'] * 100:.1f}%\"\n",
    "    if res[\"ari\"] is not None:\n",
    "        s += f\", ARI={res['ari']:.3f}\"\n",
    "    if res[\"nmi\"] is not None:\n",
    "        s += f\", NMI={res['nmi']:.3f}\"\n",
    "    s += f\", exact={res['exact_match']}\"\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e429494",
   "metadata": {},
   "source": [
    "# Binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32d0744",
   "metadata": {},
   "source": [
    "## Test Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8d6066",
   "metadata": {},
   "source": [
    "### Create Test Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1164745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create networks to test the community detection algorithms\n",
    "\n",
    "###############################################################################\n",
    "# Five Disconnected Blocks (100 nodes => 5 blocks of 20 each)\n",
    "###############################################################################\n",
    "\n",
    "def create_five_disconnected_blocks(num_nodes=100, num_blocks=5, p_in=0.8):\n",
    "    assert num_nodes % num_blocks == 0, \"num_nodes must be divisible by num_blocks\"\n",
    "    block_size = num_nodes // num_blocks\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(range(num_nodes))\n",
    "    ground_truth = np.zeros(num_nodes, dtype=int)\n",
    "    for b in range(num_blocks):\n",
    "        start = b * block_size\n",
    "        end = (b+1) * block_size\n",
    "        for i in range(start, end):\n",
    "            ground_truth[i] = b\n",
    "            for j in range(i+1, end):\n",
    "                if np.random.rand() < p_in:\n",
    "                    G.add_edge(i, j)\n",
    "    return G, ground_truth\n",
    "\n",
    "###############################################################################\n",
    "# Ten-Block Connected Graph (Various Densities + Sparse Interconnections)\n",
    "###############################################################################\n",
    "\n",
    "def create_ten_blocks_connected(block_sizes=None, p_in=None, p_out=0.01):\n",
    "    \"\"\"\n",
    "    Create a graph with 10 blocks, each with its own connection probability.\n",
    "    \n",
    "    Parameters:\n",
    "        block_sizes (list of int, optional): Sizes of the 10 blocks. If None, defaults to 10 blocks of 30 nodes each.\n",
    "        p_in (list of float, optional): Internal connection probabilities for each block. \n",
    "                                        If None, defaults to predefined densities.\n",
    "        p_out (float): Probability of connections between different blocks.\n",
    "\n",
    "    Returns:\n",
    "        G (networkx.Graph): The generated graph.\n",
    "        ground_truth (np.array): The ground-truth labels for each node.\n",
    "    \"\"\"\n",
    "    if block_sizes is None:\n",
    "        block_sizes = [30] * 10  # Default: 10 blocks of size 30\n",
    "\n",
    "    if p_in is None:\n",
    "        # Different probabilities for different densities (customizable)\n",
    "        p_in = [0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.6, 0.5, 0.4, 0.3] \n",
    "    \n",
    "    assert len(block_sizes) == 10, \"Must have 10 block sizes\"\n",
    "    assert len(p_in) == 10, \"Must specify exactly 10 internal connection probabilities\"\n",
    "\n",
    "    N = sum(block_sizes)\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(range(N))\n",
    "    ground_truth = np.zeros(N, dtype=int)\n",
    "\n",
    "    # Track block indices\n",
    "    start_indices = np.cumsum([0] + block_sizes[:-1])\n",
    "    end_indices = np.cumsum(block_sizes)\n",
    "\n",
    "    # Add intra-block edges\n",
    "    for b in range(10):\n",
    "        start, end = start_indices[b], end_indices[b]\n",
    "        for i in range(start, end):\n",
    "            ground_truth[i] = b\n",
    "            for j in range(i + 1, end):\n",
    "                if np.random.rand() < p_in[b]:\n",
    "                    G.add_edge(i, j)\n",
    "\n",
    "    # Add inter-block edges\n",
    "    for b1 in range(10):\n",
    "        for b2 in range(b1 + 1, 10):\n",
    "            start1, end1 = start_indices[b1], end_indices[b1]\n",
    "            start2, end2 = start_indices[b2], end_indices[b2]\n",
    "            for i in range(start1, end1):\n",
    "                for j in range(start2, end2):\n",
    "                    if np.random.rand() < p_out:\n",
    "                        G.add_edge(i, j)\n",
    "\n",
    "    return G, ground_truth\n",
    "\n",
    "###############################################################################\n",
    "# Generate graphs\n",
    "###############################################################################\n",
    "\n",
    "G5, truth5 = create_five_disconnected_blocks(num_nodes=100, num_blocks=5, p_in=0.5)\n",
    "G10, truth10 = create_ten_blocks_connected()\n",
    "\n",
    "###############################################################################\n",
    "# Plot graphs\n",
    "###############################################################################\n",
    "\n",
    "# Plot ground-truth communities for each graph:\n",
    "pos_G5 = nx.spring_layout(G5, seed=42)\n",
    "pos_G10 = nx.spring_layout(G10, seed=42)\n",
    "plot_ground_truth_with_domino(G5, truth5, pos=pos_G5, layout=\"custom\")\n",
    "plot_ground_truth_with_domino(G10, truth10, pos=pos_G10, layout=\"custom\")\n",
    "\n",
    "# Define the adjacency matrices\n",
    "A5 = nx.to_numpy_array(G5)\n",
    "A10 = nx.to_numpy_array(G10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3587ebc2",
   "metadata": {},
   "source": [
    "### Community Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d719ff7",
   "metadata": {},
   "source": [
    "#### SBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc242312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# G5: five disconnected blocks\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "print(\"\\n========================================\")\n",
    "print(\"Processing G5\")\n",
    "print(\"========================================\\n\")\n",
    "\n",
    "G5_bin = nx.from_numpy_array(A5, create_using=nx.Graph)\n",
    "\n",
    "res = detect(\n",
    "    G5_bin,\n",
    "    A5,\n",
    "    mode=\"binary\",\n",
    "    degree_corrected=False,\n",
    "    initial_partition=\"modularity\",\n",
    "    max_outer=10,\n",
    "    target_K=None,\n",
    "    viz={\"layout\": \"custom\", \"pos\": pos_G5},\n",
    "    report={\"print_info\": True},\n",
    ")\n",
    "\n",
    "sbm_part_5 = res[\"partition\"]\n",
    "sbm_bic_5 = res[\"bic\"]\n",
    "print(f\"G5 best BIC: {sbm_bic_5:.2f}\")\n",
    "\n",
    "sbm_labels_5 = partition_to_dict(sbm_part_5.flatten())\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# G10: ten‐block connected\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "print(\"\\n========================================\")\n",
    "print(\"Processing G10\")\n",
    "print(\"========================================\\n\")\n",
    "\n",
    "G10_bin = nx.from_numpy_array(A10, create_using=nx.Graph)\n",
    "\n",
    "res = detect(\n",
    "    G10_bin,\n",
    "    A10,\n",
    "    mode=\"binary\",\n",
    "    degree_corrected=False,\n",
    "    initial_partition=\"modularity\",\n",
    "    max_outer=10,\n",
    "    target_K=None,\n",
    "    viz={\"layout\": \"custom\", \"pos\": pos_G10},\n",
    "    report={\"print_info\": True},\n",
    ")\n",
    "\n",
    "sbm_part_10 = res[\"partition\"]\n",
    "sbm_bic_10 = res[\"bic\"]\n",
    "print(f\"G10 best BIC: {sbm_bic_10:.2f}\")\n",
    "\n",
    "sbm_labels_10 = partition_to_dict(sbm_part_10.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae1284f",
   "metadata": {},
   "source": [
    "#### Check partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39288b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- Binary: compare truth vs detected (SBM) --------\n",
    "truth_G5 = truth_as_dict(truth5)\n",
    "res_G5_sbm = compare_partitions(G5_bin, truth_G5, sbm_labels_5)\n",
    "pretty_print_result(\"G5 (binary 5-blocks, SBM)\", res_G5_sbm)\n",
    "\n",
    "truth_G10 = truth_as_dict(truth10)\n",
    "res_G10_sbm = compare_partitions(G10_bin, truth_G10, sbm_labels_10)\n",
    "pretty_print_result(\"G10 (binary 10-blocks, SBM)\", res_G10_sbm)\n",
    "\n",
    "print(\"\\n\" + \"-\" * 78)\n",
    "print(\"[Recap SBM]   \" + recap_line(\"G5\", res_G5_sbm))\n",
    "print(\"[Recap SBM]   \" + recap_line(\"G10\", res_G10_sbm))\n",
    "print(\"-\" * 78)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c781e532",
   "metadata": {},
   "source": [
    "#### dcSBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275e9220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# G5: five disconnected blocks\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "print(\"\\n========================================\")\n",
    "print(\"Processing G5\")\n",
    "print(\"========================================\\n\")\n",
    "\n",
    "G5_bin = nx.from_numpy_array(A5, create_using=nx.Graph)\n",
    "\n",
    "res = detect(\n",
    "    G5_bin,\n",
    "    A5,\n",
    "    mode=\"binary\",\n",
    "    degree_corrected=True,\n",
    "    initial_partition=\"modularity\",\n",
    "    max_outer=10,\n",
    "    target_K=None,\n",
    "    viz={\"layout\": \"custom\", \"pos\": pos_G5},\n",
    "    report={\"print_info\": True},\n",
    ")\n",
    "\n",
    "dcsbm_part_5 = res[\"partition\"]\n",
    "dcsbm_bic_5 = res[\"bic\"]\n",
    "print(f\"G5 best BIC: {dcsbm_bic_5:.2f}\")\n",
    "\n",
    "dcsbm_labels_5 = partition_to_dict(dcsbm_part_5.flatten())\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# G10: ten‐block connected\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "print(\"\\n========================================\")\n",
    "print(\"Processing G10\")\n",
    "print(\"========================================\\n\")\n",
    "\n",
    "G10_bin = nx.from_numpy_array(A10, create_using=nx.Graph)\n",
    "\n",
    "res = detect(\n",
    "    G10_bin,\n",
    "    A10,\n",
    "    mode=\"binary\",\n",
    "    degree_corrected=True,\n",
    "    initial_partition=\"modularity\",\n",
    "    max_outer=10,\n",
    "    target_K=None,\n",
    "    viz={\"layout\": \"custom\", \"pos\": pos_G10},\n",
    "    report={\"print_info\": True},\n",
    ")\n",
    "\n",
    "dcsbm_part_10 = res[\"partition\"]\n",
    "dcsbm_bic_10 = res[\"bic\"]\n",
    "print(f\"G10 best BIC: {dcsbm_bic_10:.2f}\")\n",
    "\n",
    "dcsbm_labels_10 = partition_to_dict(dcsbm_part_10.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1863903f",
   "metadata": {},
   "source": [
    "#### Check partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804c2f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- Binary: compare truth vs detected (dcSBM) --------\n",
    "truth_G5 = truth_as_dict(truth5)\n",
    "res_G5_dcsbm = compare_partitions(G5_bin, truth_G5, dcsbm_labels_5)\n",
    "pretty_print_result(\"G5 (binary 5-blocks, dcSBM)\", res_G5_dcsbm)\n",
    "\n",
    "truth_G10 = truth_as_dict(truth10)\n",
    "res_G10_dcsbm = compare_partitions(G10_bin, truth_G10, dcsbm_labels_10)\n",
    "pretty_print_result(\"G10 (binary 10-blocks, dcSBM)\", res_G10_dcsbm)\n",
    "\n",
    "print(\"\\n\" + \"-\" * 78)\n",
    "print(\"[Recap dcSBM] \" + recap_line(\"G5\", res_G5_dcsbm))\n",
    "print(\"[Recap dcSBM] \" + recap_line(\"G10\", res_G10_dcsbm))\n",
    "print(\"-\" * 78)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab31881",
   "metadata": {},
   "source": [
    "# Signed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7730edc9",
   "metadata": {},
   "source": [
    "## Test Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a5dc9f",
   "metadata": {},
   "source": [
    "### Create Test Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ae8a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Utilities: sample signed SBM with tri-nomial dyads (+, −, 0)\n",
    "# =============================================================================\n",
    "def _block_ranges(sizes: List[int]) -> List[Tuple[int, int]]:\n",
    "    \"\"\"Return [(start, end), ...] ranges for each block (0-indexed, end-exclusive).\"\"\"\n",
    "    starts = np.cumsum([0] + sizes[:-1])\n",
    "    ends = np.cumsum(sizes)\n",
    "    return list(zip(starts, ends))\n",
    "\n",
    "\n",
    "def _sample_signed_blockpair(\n",
    "    Ap: np.ndarray,\n",
    "    An: np.ndarray,\n",
    "    i_range: Tuple[int, int],\n",
    "    j_range: Tuple[int, int],\n",
    "    p_pos: float,\n",
    "    p_neg: float,\n",
    "    same_block: bool,\n",
    "    rng: np.random.Generator\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Fill Ap/An for block-pair with tri-nomial sampling.\n",
    "    Exactly one of {+, −, 0} per dyad.\n",
    "\n",
    "    Ap/An are symmetric 0/1 adjacency matrices (no self-loops).\n",
    "    \"\"\"\n",
    "    i0, i1 = i_range\n",
    "    j0, j1 = j_range\n",
    "    if same_block:\n",
    "        # iterate strictly upper triangle within the block\n",
    "        for i in range(i0, i1):\n",
    "            for j in range(i + 1, i1):\n",
    "                u = rng.random()\n",
    "                if u < p_pos:\n",
    "                    Ap[i, j] = Ap[j, i] = 1\n",
    "                elif u < p_pos + p_neg:\n",
    "                    An[i, j] = An[j, i] = 1\n",
    "        return\n",
    "\n",
    "    # r != s: full bipartite rectangle\n",
    "    for i in range(i0, i1):\n",
    "        for j in range(j0, j1):\n",
    "            u = rng.random()\n",
    "            if u < p_pos:\n",
    "                Ap[i, j] = Ap[j, i] = 1\n",
    "            elif u < p_pos + p_neg:\n",
    "                An[i, j] = An[j, i] = 1\n",
    "\n",
    "\n",
    "def sample_signed_sbm(\n",
    "    block_sizes: List[int],\n",
    "    Ppos: np.ndarray,  # shape (B,B), symmetric, entries in [0,1]\n",
    "    Pneg: np.ndarray,  # shape (B,B), symmetric, entries in [0,1], with Ppos+Pneg ≤ 1\n",
    "    seed: int = 42\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Sample a signed SBM with B blocks of given sizes and block-pair probabilities.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Apos, Aneg, truth\n",
    "      Apos/Aneg: NxN (0/1) symmetric +/− adjacency matrices, no self-loops.\n",
    "      truth    : (N,) block labels in {0..B-1}.\n",
    "    \"\"\"\n",
    "    assert Ppos.shape == Pneg.shape\n",
    "    B = Ppos.shape[0]\n",
    "    assert B == len(block_sizes), \"P matrices and block_sizes disagree\"\n",
    "    assert np.allclose(Ppos, Ppos.T) and np.allclose(Pneg, Pneg.T), \"Ppos/Pneg must be symmetric\"\n",
    "    assert np.all(Ppos >= 0) and np.all(Pneg >= 0), \"negative probabilities!\"\n",
    "    assert np.all(Ppos + Pneg <= 1 + 1e-12), \"Ppos + Pneg must be ≤ 1\"\n",
    "\n",
    "    N = int(np.sum(block_sizes))\n",
    "    Apos = np.zeros((N, N), dtype=int)\n",
    "    Aneg = np.zeros((N, N), dtype=int)\n",
    "\n",
    "    # ground-truth labels\n",
    "    truth = np.empty(N, dtype=int)\n",
    "    ranges = _block_ranges(block_sizes)\n",
    "    for r, (a, b) in enumerate(ranges):\n",
    "        truth[a:b] = r\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # fill per block pair\n",
    "    for r in range(B):\n",
    "        # diagonal\n",
    "        _sample_signed_blockpair(\n",
    "            Apos, Aneg, ranges[r], ranges[r], Ppos[r, r], Pneg[r, r], True, rng\n",
    "        )\n",
    "        # off-diagonals\n",
    "        for s in range(r + 1, B):\n",
    "            _sample_signed_blockpair(\n",
    "                Apos, Aneg, ranges[r], ranges[s], Ppos[r, s], Pneg[r, s], False, rng\n",
    "            )\n",
    "\n",
    "    # zero diagonal\n",
    "    np.fill_diagonal(Apos, 0)\n",
    "    np.fill_diagonal(Aneg, 0)\n",
    "    return Apos, Aneg, truth\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Easy case: 5 disconnected “friend groups” with negative between-group ties\n",
    "# =============================================================================\n",
    "def create_easy_signed_5blocks(\n",
    "    num_blocks: int = 5,\n",
    "    block_size: int = 20,\n",
    "    p_in_pos: float = 0.60,\n",
    "    p_in_neg: float = 0.02,\n",
    "    p_out_pos: float = 0.03,\n",
    "    p_out_neg: float = 0.25,\n",
    "    seed: int = 42\n",
    "):\n",
    "    \"\"\"\n",
    "    Five equal communities (strongly positive inside, mostly negative across).\n",
    "    \"\"\"\n",
    "    sizes = [block_size] * num_blocks\n",
    "    B = num_blocks\n",
    "\n",
    "    Ppos = np.full((B, B), p_out_pos, dtype=float)\n",
    "    Pneg = np.full((B, B), p_out_neg, dtype=float)\n",
    "\n",
    "    # stronger + inside; almost no − inside\n",
    "    np.fill_diagonal(Ppos, p_in_pos)\n",
    "    np.fill_diagonal(Pneg, p_in_neg)\n",
    "\n",
    "    # ensure Ppos+Pneg ≤ 1\n",
    "    assert np.all(Ppos + Pneg <= 1.0 + 1e-12)\n",
    "\n",
    "    Apos, Aneg, truth = sample_signed_sbm(sizes, Ppos, Pneg, seed=seed)\n",
    "    return Apos, Aneg, truth\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Harder case: 8 blocks, two macro-alliances with exceptions (heterogeneous)\n",
    "# =============================================================================\n",
    "def create_hard_signed_8blocks(\n",
    "    sizes: List[int] = None,\n",
    "    seed: int = 7\n",
    "):\n",
    "    \"\"\"\n",
    "    8 blocks (≤ 300 total nodes) with two macro-alliances:\n",
    "      Group A = {0,1,2,3}, Group B = {4,5,6,7}\n",
    "    - Inside blocks: moderate-high positive density, tiny negative.\n",
    "    - Within the same macro-alliance: modest positive, tiny negative.\n",
    "    - Across alliances: weak positive, stronger negative.\n",
    "    - A few 'exception edges' flip the sign pattern to add difficulty.\n",
    "    \"\"\"\n",
    "    if sizes is None:\n",
    "        sizes = [36, 30, 28, 26, 28, 30, 32, 30]  # sum = 240\n",
    "\n",
    "    B = 8\n",
    "    assert len(sizes) == B\n",
    "    Ppos = np.zeros((B, B), dtype=float)\n",
    "    Pneg = np.zeros((B, B), dtype=float)\n",
    "\n",
    "    # Baselines\n",
    "    for r in range(B):\n",
    "        for s in range(B):\n",
    "            if r == s:\n",
    "                Ppos[r, s] = 0.55  # within-block + edges\n",
    "                Pneg[r, s] = 0.02\n",
    "            else:\n",
    "                # default cross-block\n",
    "                Ppos[r, s] = 0.05\n",
    "                Pneg[r, s] = 0.10\n",
    "\n",
    "    # Macro-alliances: {0,1,2,3} vs {4,5,6,7}\n",
    "    A_side = {0, 1, 2, 3}\n",
    "    B_side = {4, 5, 6, 7}\n",
    "    for r in A_side:\n",
    "        for s in A_side:\n",
    "            if r < s:\n",
    "                Ppos[r, s] = Ppos[s, r] = 0.18\n",
    "                Pneg[r, s] = Pneg[s, r] = 0.03\n",
    "    for r in B_side:\n",
    "        for s in B_side:\n",
    "            if r < s:\n",
    "                Ppos[r, s] = Ppos[s, r] = 0.17\n",
    "                Pneg[r, s] = Pneg[s, r] = 0.03\n",
    "\n",
    "    # Across alliances: mostly negative rivalry\n",
    "    for r in A_side:\n",
    "        for s in B_side:\n",
    "            Ppos[r, s] = Ppos[s, r] = 0.03\n",
    "            Pneg[r, s] = Pneg[s, r] = 0.18\n",
    "\n",
    "    # A few deliberate exceptions to break the clean pattern:\n",
    "    # strong + between blocks (2,5) and (1,4); strong − within pair (3,2)\n",
    "    Ppos[2, 5] = Ppos[5, 2] = 0.20\n",
    "    Pneg[2, 5] = Pneg[5, 2] = 0.02\n",
    "\n",
    "    Ppos[1, 4] = Ppos[4, 1] = 0.20\n",
    "    Pneg[1, 4] = Pneg[4, 1] = 0.02\n",
    "\n",
    "    # a strong negative tie between (2,3) despite same macro-alliance\n",
    "    Ppos[2, 3] = Ppos[3, 2] = 0.06\n",
    "    Pneg[2, 3] = Pneg[3, 2] = 0.20\n",
    "\n",
    "    # sanity: Ppos + Pneg ≤ 1\n",
    "    assert np.all(Ppos + Pneg <= 1.0 + 1e-12)\n",
    "\n",
    "    Apos, Aneg, truth = sample_signed_sbm(sizes, Ppos, Pneg, seed=seed)\n",
    "    return Apos, Aneg, truth\n",
    "\n",
    "# ------------------ Generate graphs ------------------\n",
    "\n",
    "# Easy signed (5 blocks)\n",
    "Apos5, Aneg5, truth5 = create_easy_signed_5blocks(\n",
    "    num_blocks=5, block_size=20,\n",
    "    p_in_pos=0.60, p_in_neg=0.02,\n",
    "    p_out_pos=0.03, p_out_neg=0.25,\n",
    "    seed=123\n",
    ")\n",
    "\n",
    "# Hard signed (8 blocks)\n",
    "Apos8, Aneg8, truth8 = create_hard_signed_8blocks()\n",
    "\n",
    "# Build union graphs (edge if + or −), as in your binary case’s use of nx.from_numpy_array\n",
    "Asign5 = Apos5 - Aneg5\n",
    "Asign8 = Apos8 - Aneg8\n",
    "G5_signed = nx.from_numpy_array((Asign5 != 0).astype(int), create_using=nx.Graph)\n",
    "G8_signed = nx.from_numpy_array((Asign8 != 0).astype(int), create_using=nx.Graph)\n",
    "\n",
    "# Plot ground truth (exactly like you do for binary)\n",
    "pos_S5 = community_layout(G5_signed, {i: int(truth5[i]) for i in range(len(truth5))}, seed=42)\n",
    "pos_S8 = community_layout(G8_signed, {i: int(truth8[i]) for i in range(len(truth8))}, seed=7)\n",
    "plot_ground_truth_with_domino(G5_signed, truth5, pos=pos_S5, Apos=Apos5, Aneg=Aneg5, layout=\"custom\");\n",
    "plot_ground_truth_with_domino(G8_signed, truth8, pos=pos_S8, Apos=Apos8, Aneg=Aneg8, layout=\"custom\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e49ea39",
   "metadata": {},
   "source": [
    "### Community Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070ae92b",
   "metadata": {},
   "source": [
    "#### sSBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e915a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# S5: five signed blocks  (analog of your G5 section)\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "print(\"\\n========================================\")\n",
    "print(\"Processing S5 (signed 5-blocks)\")\n",
    "print(\"========================================\\n\")\n",
    "\n",
    "res = detect(\n",
    "    G5_signed,\n",
    "    Asign5,\n",
    "    mode=\"signed\",\n",
    "    degree_corrected=False,\n",
    "    initial_partition=\"pos_modularity\",\n",
    "    max_outer=10,\n",
    "    target_K=None,\n",
    "    viz={\"layout\": \"custom\", \"pos\": pos_S5, \"Apos\": Apos5, \"Aneg\": Aneg5},\n",
    "    report={\"print_info\": True},\n",
    ")\n",
    "\n",
    "sSBM_part_5 = res[\"partition\"]\n",
    "sSBM_bic_5 = res[\"bic\"]\n",
    "print(f\"S5 best BIC (sSBM): {sSBM_bic_5:.2f}\")\n",
    "\n",
    "sSBM_labels_5 = partition_to_dict(sSBM_part_5.flatten())\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# S8: eight signed blocks  (analog of your G10 section)\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "print(\"\\n========================================\")\n",
    "print(\"Processing S8 (signed 8-blocks)\")\n",
    "print(\"========================================\\n\")\n",
    "\n",
    "res = detect(\n",
    "    G8_signed,\n",
    "    Asign8,\n",
    "    mode=\"signed\",\n",
    "    degree_corrected=False,\n",
    "    initial_partition=\"pos_modularity\",\n",
    "    max_outer=10,\n",
    "    target_K=None,\n",
    "    viz={\"layout\": \"custom\", \"pos\": pos_S8, \"Apos\": Apos8, \"Aneg\": Aneg8},\n",
    "    report={\"print_info\": True},\n",
    ")\n",
    "\n",
    "sSBM_part_8 = res[\"partition\"]\n",
    "sSBM_bic_8 = res[\"bic\"]\n",
    "print(f\"S8 best BIC (sSBM): {sSBM_bic_8:.2f}\")\n",
    "\n",
    "sSBM_labels_8 = partition_to_dict(sSBM_part_8.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24745629",
   "metadata": {},
   "source": [
    "#### Check partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2eb2d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- S5 comparison --------\n",
    "truth_S5 = {i: int(truth5[i]) for i in range(len(truth5))}\n",
    "# Use your detected labels (dict or Partition). You already built sSBM_labels_5:\n",
    "res_S5 = compare_partitions(G5_signed, truth_S5, sSBM_labels_5)\n",
    "pretty_print_result(\"S5 (signed 5-blocks, sSBM)\", res_S5)\n",
    "\n",
    "# -------- S8 comparison --------\n",
    "truth_S8 = {i: int(truth8[i]) for i in range(len(truth8))}\n",
    "# You already built sSBM_labels_8:\n",
    "res_S8 = compare_partitions(G8_signed, truth_S8, sSBM_labels_8)\n",
    "pretty_print_result(\"S8 (signed 8-blocks, sSBM)\", res_S8)\n",
    "\n",
    "# -------- Compact one-line recap --------\n",
    "print(\"\\n\" + \"-\"*78)\n",
    "print(f\"[Recap] S5: acc={res_S5['accuracy']*100:.1f}%\"\n",
    "      + (f\", ARI={res_S5['ari']:.3f}\" if res_S5['ari'] is not None else \"\")\n",
    "      + (f\", NMI={res_S5['nmi']:.3f}\" if res_S5['nmi'] is not None else \"\")\n",
    "      + f\", exact={res_S5['exact_match']}\")\n",
    "print(f\"[Recap] S8: acc={res_S8['accuracy']*100:.1f}%\"\n",
    "      + (f\", ARI={res_S8['ari']:.3f}\" if res_S8['ari'] is not None else \"\")\n",
    "      + (f\", NMI={res_S8['nmi']:.3f}\" if res_S8['nmi'] is not None else \"\")\n",
    "      + f\", exact={res_S8['exact_match']}\")\n",
    "print(\"-\"*78)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a688964",
   "metadata": {},
   "source": [
    "#### sdcSBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b1b857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# S5: five signed blocks  (analog of your G5 section)\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "print(\"\\n========================================\")\n",
    "print(\"Processing S5 (signed 5-blocks)\")\n",
    "print(\"========================================\\n\")\n",
    "\n",
    "res = detect(\n",
    "    G5_signed,\n",
    "    Asign5,\n",
    "    mode=\"signed\",\n",
    "    degree_corrected=True,\n",
    "    initial_partition=\"pos_modularity\",\n",
    "    max_outer=10,\n",
    "    target_K=None,\n",
    "    viz={\"layout\": \"custom\", \"pos\": pos_S5, \"Apos\": Apos5, \"Aneg\": Aneg5},\n",
    "    report={\"print_info\": True},\n",
    ")\n",
    "\n",
    "sdcSBM_part_5 = res[\"partition\"]\n",
    "sdcSBM_bic_5 = res[\"bic\"]\n",
    "print(f\"S5 best BIC (sdcSBM): {sdcSBM_bic_5:.2f}\")\n",
    "\n",
    "sdcSBM_labels_5 = partition_to_dict(sdcSBM_part_5.flatten())\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# S8: eight signed blocks  (analog of your G10 section)\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "print(\"\\n========================================\")\n",
    "print(\"Processing S8 (signed 8-blocks)\")\n",
    "print(\"========================================\\n\")\n",
    "\n",
    "res = detect(\n",
    "    G8_signed,\n",
    "    Asign8,\n",
    "    mode=\"signed\",\n",
    "    degree_corrected=True,\n",
    "    initial_partition=\"pos_modularity\",\n",
    "    max_outer=10,\n",
    "    target_K=None,\n",
    "    viz={\"layout\": \"custom\", \"pos\": pos_S8, \"Apos\": Apos8, \"Aneg\": Aneg8},\n",
    "    report={\"print_info\": True},\n",
    ")\n",
    "\n",
    "sdcSBM_part_8 = res[\"partition\"]\n",
    "sdcSBM_bic_8 = res[\"bic\"]\n",
    "print(f\"S8 best BIC (sdcSBM): {sdcSBM_bic_8:.2f}\")\n",
    "\n",
    "sdcSBM_labels_8 = partition_to_dict(sdcSBM_part_8.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16633f9",
   "metadata": {},
   "source": [
    "#### Check partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b463bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- S5 (sdcSBM) --------\n",
    "truth_S5 = {i: int(truth5[i]) for i in range(len(truth5))}\n",
    "res_S5_sdc = compare_partitions(G5_signed, truth_S5, sdcSBM_labels_5)\n",
    "pretty_print_result(\"S5 (signed 5-blocks, sdcSBM)\", res_S5_sdc)\n",
    "\n",
    "# -------- S8 (sdcSBM) --------\n",
    "truth_S8 = {i: int(truth8[i]) for i in range(len(truth8))}\n",
    "res_S8_sdc = compare_partitions(G8_signed, truth_S8, sdcSBM_labels_8)\n",
    "pretty_print_result(\"S8 (signed 8-blocks, sdcSBM)\", res_S8_sdc)\n",
    "\n",
    "# -------- Compact one-line recap (sdcSBM) --------\n",
    "print(\"\\n\" + \"-\"*78)\n",
    "print(f\"[Recap sdcSBM] S5: acc={res_S5_sdc['accuracy']*100:.1f}%\"\n",
    "      + (f\", ARI={res_S5_sdc['ari']:.3f}\" if res_S5_sdc['ari'] is not None else \"\")\n",
    "      + (f\", NMI={res_S5_sdc['nmi']:.3f}\" if res_S5_sdc['nmi'] is not None else \"\")\n",
    "      + f\", exact={res_S5_sdc['exact_match']}\")\n",
    "print(f\"[Recap sdcSBM] S8: acc={res_S8_sdc['accuracy']*100:.1f}%\"\n",
    "      + (f\", ARI={res_S8_sdc['ari']:.3f}\" if res_S8_sdc['ari'] is not None else \"\")\n",
    "      + (f\", NMI={res_S8_sdc['nmi']:.3f}\" if res_S8_sdc['nmi'] is not None else \"\")\n",
    "      + f\", exact={res_S8_sdc['exact_match']}\")\n",
    "print(\"-\"*78)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76699c6",
   "metadata": {},
   "source": [
    "# Weighted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04a9411",
   "metadata": {},
   "source": [
    "## Test Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f32a317",
   "metadata": {},
   "source": [
    "### Create Test Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a6c7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Helpers\n",
    "###############################################################################\n",
    "\n",
    "def _geom_sample(mean):\n",
    "    \"\"\"\n",
    "    Geometric on {0,1,2,...} with mean=mean.\n",
    "    Parameterization: p = 1/(1+mean); w = Geom(p on {1,2,...}) - 1\n",
    "    \"\"\"\n",
    "    if mean <= 0:\n",
    "        return 0\n",
    "    p = 1.0 / (1.0 + float(mean))\n",
    "    return np.random.geometric(p) - 1\n",
    "\n",
    "###############################################################################\n",
    "# Five Disconnected Blocks (weighted)\n",
    "###############################################################################\n",
    "\n",
    "def create_five_disconnected_blocks_weighted(\n",
    "    num_nodes=100, num_blocks=5, mu_in=1.5\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a weighted graph with 'num_blocks' disconnected blocks.\n",
    "    For i<j within the same block, w_ij ~ Geometric(mean=mu_in) on {0,1,2,...}.\n",
    "    Cross-block weights are 0 (disconnected).\n",
    "    \"\"\"\n",
    "    assert num_nodes % num_blocks == 0, \"num_nodes must be divisible by num_blocks\"\n",
    "    block_size = num_nodes // num_blocks\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(range(num_nodes))\n",
    "    ground_truth = np.zeros(num_nodes, dtype=int)\n",
    "\n",
    "    for b in range(num_blocks):\n",
    "        start = b * block_size\n",
    "        end = (b + 1) * block_size\n",
    "        for i in range(start, end):\n",
    "            ground_truth[i] = b\n",
    "            for j in range(i + 1, end):\n",
    "                w = _geom_sample(mu_in)\n",
    "                if w > 0:\n",
    "                    G.add_edge(i, j, weight=int(w))\n",
    "    return G, ground_truth\n",
    "\n",
    "###############################################################################\n",
    "# Ten-Block Connected Graph (weighted; heterogeneous within means + sparse cross)\n",
    "###############################################################################\n",
    "\n",
    "def create_ten_blocks_connected_weighted(\n",
    "    block_sizes=None,\n",
    "    mu_in=None,\n",
    "    mu_out=0.05\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a weighted graph with 10 blocks. For i<j in block b, w_ij ~ Geom(mean=mu_in[b]).\n",
    "    For cross-block pairs, w_ij ~ Geom(mean=mu_out), typically very small.\n",
    "    \"\"\"\n",
    "    if block_sizes is None:\n",
    "        block_sizes = [30] * 10\n",
    "\n",
    "    if mu_in is None:\n",
    "        # customizable within-block means (higher → denser/heavier)\n",
    "        mu_in = [1.5, 1.2, 1.0, 0.8, 0.6, 0.4, 1.0, 0.8, 0.6, 0.4]\n",
    "\n",
    "    assert len(block_sizes) == 10, \"Must have 10 block sizes\"\n",
    "    assert len(mu_in) == 10, \"Must specify exactly 10 within-block means\"\n",
    "\n",
    "    N = sum(block_sizes)\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(range(N))\n",
    "    ground_truth = np.zeros(N, dtype=int)\n",
    "\n",
    "    # Block boundaries\n",
    "    start_indices = np.cumsum([0] + block_sizes[:-1])\n",
    "    end_indices = np.cumsum(block_sizes)\n",
    "\n",
    "    # Intra-block weights\n",
    "    for b in range(10):\n",
    "        start, end = start_indices[b], end_indices[b]\n",
    "        for i in range(start, end):\n",
    "            ground_truth[i] = b\n",
    "            for j in range(i + 1, end):\n",
    "                w = _geom_sample(mu_in[b])\n",
    "                if w > 0:\n",
    "                    G.add_edge(i, j, weight=int(w))\n",
    "\n",
    "    # Inter-block weights (sparse / tiny means)\n",
    "    for b1 in range(10):\n",
    "        for b2 in range(b1 + 1, 10):\n",
    "            start1, end1 = start_indices[b1], end_indices[b1]\n",
    "            start2, end2 = start_indices[b2], end_indices[b2]\n",
    "            for i in range(start1, end1):\n",
    "                for j in range(start2, end2):\n",
    "                    w = _geom_sample(mu_out)\n",
    "                    if w > 0:\n",
    "                        G.add_edge(i, j, weight=int(w))\n",
    "\n",
    "    return G, ground_truth\n",
    "\n",
    "###############################################################################\n",
    "# Generate graphs (weighted)\n",
    "###############################################################################\n",
    "\n",
    "G5w, truth5w = create_five_disconnected_blocks_weighted(num_nodes=100, num_blocks=5, mu_in=1.5)\n",
    "G10w, truth10w = create_ten_blocks_connected_weighted()\n",
    "\n",
    "###############################################################################\n",
    "# Plot graphs (weighted)\n",
    "###############################################################################\n",
    "\n",
    "pos_G5w = nx.spring_layout(G5w, seed=42)\n",
    "pos_G10w = nx.spring_layout(G10w, seed=42)\n",
    "plot_ground_truth_with_domino(G5w, truth5w, pos=pos_G5w, layout=\"custom\", title_prefix=\"G5w_truth\")\n",
    "plot_ground_truth_with_domino(G10w, truth10w, pos=pos_G10w, layout=\"custom\", title_prefix=\"G10w_truth\")\n",
    "\n",
    "# Weighted adjacency matrices\n",
    "A5w  = nx.to_numpy_array(G5w,  weight='weight', dtype=float)\n",
    "A10w = nx.to_numpy_array(G10w, weight='weight', dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdea6cf0",
   "metadata": {},
   "source": [
    "### Community Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d1e669",
   "metadata": {},
   "source": [
    "#### wSBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba0e993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# G5w: five disconnected blocks — Weighted SBM (no degree correction)\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "print(\"\\n========================================\")\n",
    "print(\"Processing G5 (weighted, wSBM)\")\n",
    "print(\"========================================\\n\")\n",
    "\n",
    "G5w_nx = nx.from_numpy_array(A5w)  # weights included by default\n",
    "\n",
    "res = detect(\n",
    "    G5w_nx,\n",
    "    A5w,\n",
    "    mode=\"weighted\",\n",
    "    degree_corrected=False,\n",
    "    initial_partition=\"modularity\",\n",
    "    max_outer=10,\n",
    "    target_K=None,\n",
    "    viz={\"layout\": \"custom\", \"pos\": pos_G5w},\n",
    "    report={\"print_info\": True},\n",
    ")\n",
    "\n",
    "wsbm_part_5 = res[\"partition\"]\n",
    "wsbm_bic_5 = res[\"bic\"]\n",
    "print(f\"G5 (weighted) best BIC (wSBM): {wsbm_bic_5:.2f}\")\n",
    "\n",
    "wsbm_labels_5 = partition_to_dict(wsbm_part_5.flatten())\n",
    "\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# G10w: ten-block connected — Weighted SBM (no degree correction)\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "print(\"\\n========================================\")\n",
    "print(\"Processing G10 (weighted, wSBM)\")\n",
    "print(\"========================================\\n\")\n",
    "\n",
    "G10w_nx = nx.from_numpy_array(A10w)\n",
    "\n",
    "res = detect(\n",
    "    G10w_nx,\n",
    "    A10w,\n",
    "    mode=\"weighted\",\n",
    "    degree_corrected=False,\n",
    "    initial_partition=\"modularity\",\n",
    "    max_outer=10,\n",
    "    target_K=None,\n",
    "    viz={\"layout\": \"custom\", \"pos\": pos_G10w},\n",
    "    report={\"print_info\": True},\n",
    ")\n",
    "\n",
    "wsbm_part_10 = res[\"partition\"]\n",
    "wsbm_bic_10 = res[\"bic\"]\n",
    "print(f\"G10 (weighted) best BIC (wSBM): {wsbm_bic_10:.2f}\")\n",
    "\n",
    "wsbm_labels_10 = partition_to_dict(wsbm_part_10.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c398c4a",
   "metadata": {},
   "source": [
    "#### Check partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712abdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- G5w (wSBM) --------\n",
    "truth_G5w = {i: int(truth5w[i]) for i in range(len(truth5w))}\n",
    "res_G5w_wsbm = compare_partitions(G5w_nx, truth_G5w, wsbm_labels_5)\n",
    "pretty_print_result(\"G5w (weighted 5-blocks, wSBM)\", res_G5w_wsbm)\n",
    "\n",
    "# -------- G10w (wSBM) --------\n",
    "truth_G10w = {i: int(truth10w[i]) for i in range(len(truth10w))}\n",
    "res_G10w_wsbm = compare_partitions(G10w_nx, truth_G10w, wsbm_labels_10)\n",
    "pretty_print_result(\"G10w (weighted 10-blocks, wSBM)\", res_G10w_wsbm)\n",
    "\n",
    "print(\"\\n\" + \"-\"*78)\n",
    "print(f\"[Recap wSBM]  G5w: acc={res_G5w_wsbm['accuracy']*100:.1f}%\"\n",
    "      + (f\", ARI={res_G5w_wsbm['ari']:.3f}\" if res_G5w_wsbm['ari'] is not None else \"\")\n",
    "      + (f\", NMI={res_G5w_wsbm['nmi']:.3f}\" if res_G5w_wsbm['nmi'] is not None else \"\")\n",
    "      + f\", exact={res_G5w_wsbm['exact_match']}\")\n",
    "print(f\"[Recap wSBM]  G10w: acc={res_G10w_wsbm['accuracy']*100:.1f}%\"\n",
    "      + (f\", ARI={res_G10w_wsbm['ari']:.3f}\" if res_G10w_wsbm['ari'] is not None else \"\")\n",
    "      + (f\", NMI={res_G10w_wsbm['nmi']:.3f}\" if res_G10w_wsbm['nmi'] is not None else \"\")\n",
    "      + f\", exact={res_G10w_wsbm['exact_match']}\")\n",
    "print(\"-\"*78)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb98086",
   "metadata": {},
   "source": [
    "#### wdcSBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5cc296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# G5w: five disconnected blocks — Weighted dcSBM\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "print(\"\\n========================================\")\n",
    "print(\"Processing G5 (weighted, wdcSBM)\")\n",
    "print(\"========================================\\n\")\n",
    "\n",
    "res = detect(\n",
    "    G5w_nx,\n",
    "    A5w,\n",
    "    mode=\"weighted\",\n",
    "    degree_corrected=True,\n",
    "    initial_partition=\"modularity\",\n",
    "    max_outer=10,\n",
    "    target_K=None,\n",
    "    viz={\"layout\": \"custom\", \"pos\": pos_G5w},\n",
    "    report={\"print_info\": True},\n",
    ")\n",
    "\n",
    "wdcsbm_part_5 = res[\"partition\"]\n",
    "wdcsbm_bic_5 = res[\"bic\"]\n",
    "print(f\"G5 (weighted) best BIC (wdcSBM): {wdcsbm_bic_5:.2f}\")\n",
    "\n",
    "wdcsbm_labels_5 = partition_to_dict(wdcsbm_part_5.flatten())\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# G10w: ten-block connected — Weighted dcSBM\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "print(\"\\n========================================\")\n",
    "print(\"Processing G10 (weighted, wdcSBM)\")\n",
    "print(\"========================================\\n\")\n",
    "\n",
    "res = detect(\n",
    "    G10w_nx,\n",
    "    A10w,\n",
    "    mode=\"weighted\",\n",
    "    degree_corrected=True,\n",
    "    initial_partition=\"modularity\",\n",
    "    max_outer=10,\n",
    "    target_K=None,\n",
    "    viz={\"layout\": \"custom\", \"pos\": pos_G10w},\n",
    "    report={\"print_info\": True},\n",
    ")\n",
    "\n",
    "wdcsbm_part_10 = res[\"partition\"]\n",
    "wdcsbm_bic_10 = res[\"bic\"]\n",
    "print(f\"G10 (weighted) best BIC (wdcSBM): {wdcsbm_bic_10:.2f}\")\n",
    "\n",
    "wdcsbm_labels_10 = partition_to_dict(wdcsbm_part_10.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ce7276",
   "metadata": {},
   "source": [
    "#### Check partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cbe4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- G5w (wdcSBM) --------\n",
    "res_G5w_wdcsbm = compare_partitions(G5w_nx, truth_G5w, wdcsbm_labels_5)\n",
    "pretty_print_result(\"G5w (weighted 5-blocks, wdcSBM)\", res_G5w_wdcsbm)\n",
    "\n",
    "# -------- G10w (wdcSBM) --------\n",
    "res_G10w_wdcsbm = compare_partitions(G10w_nx, truth_G10w, wdcsbm_labels_10)\n",
    "pretty_print_result(\"G10w (weighted 10-blocks, wdcSBM)\", res_G10w_wdcsbm)\n",
    "\n",
    "print(\"\\n\" + \"-\"*78)\n",
    "print(f\"[Recap wdcSBM] G5w: acc={res_G5w_wdcsbm['accuracy']*100:.1f}%\"\n",
    "      + (f\", ARI={res_G5w_wdcsbm['ari']:.3f}\" if res_G5w_wdcsbm['ari'] is not None else \"\")\n",
    "      + (f\", NMI={res_G5w_wdcsbm['nmi']:.3f}\" if res_G5w_wdcsbm['nmi'] is not None else \"\")\n",
    "      + f\", exact={res_G5w_wdcsbm['exact_match']}\")\n",
    "print(f\"[Recap wdcSBM] G10w: acc={res_G10w_wdcsbm['accuracy']*100:.1f}%\"\n",
    "      + (f\", ARI={res_G10w_wdcsbm['ari']:.3f}\" if res_G10w_wdcsbm['ari'] is not None else \"\")\n",
    "      + (f\", NMI={res_G10w_wdcsbm['nmi']:.3f}\" if res_G10w_wdcsbm['nmi'] is not None else \"\")\n",
    "      + f\", exact={res_G10w_wdcsbm['exact_match']}\")\n",
    "print(\"-\"*78)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
